{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a22fcba3-ca4b-40e9-bc93-14712b8b7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pennylane import numpy as np\n",
    "from tqdm import tqdm\n",
    "#from qbmqsp.qbm import QBM\n",
    "from qbmqsp.utils import construct_multi_fcqbm_pauli_strings\n",
    "from gen_data import xxz_gibbs_state, basis_encoding, gen_boltzmann_dist, gen_discrete_gauss_dist\n",
    "from qbmqsp.src.utils import import_dataset, split_dataset_labels, split_data\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, f1_score,\n",
    "                             precision_score, recall_score)\n",
    "import scipy.linalg as spl\n",
    "from pathlib import Path\n",
    "import pennylane as qml\n",
    "\n",
    "from pennylane.pauli.utils import string_to_pauli_word\n",
    "\n",
    "from qbmqsp.hamiltonian import Hamiltonian\n",
    "from qbmqsp.qsp_phase_engine import QSPPhaseEngine\n",
    "from qbmqsp.qevt import QEVT\n",
    "from qbmqsp.rel_ent import relative_entropy\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fff30e5b-e134-4827-a3b9-be095915b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pauli_strings_tfim(num_qubits,n_visible,restricted=False):\n",
    "    \"\"\"\n",
    "    Generate Pauli strings for a transverse field Ising model as a \n",
    "    boltzmann machine .\n",
    "    \n",
    "    Parameters:\n",
    "    num_qubits (int): Number of qubits in the quantum Boltzmann machine.\n",
    "    n_visible (int): Number if visible units.\n",
    "    \n",
    "    Returns:\n",
    "    list: List of Pauli strings representing the Hamiltonian.\n",
    "    \"\"\"\n",
    "    pauli_strings = []\n",
    "\n",
    "    # Local transverse field terms (X_i)\n",
    "    for i in range(num_qubits):\n",
    "        pauli_string = ['I'] * num_qubits\n",
    "        pauli_string[i] = 'Z'\n",
    "        pauli_strings.append(''.join(pauli_string))\n",
    "\n",
    "    # Interaction terms (Z_i Z_j)\n",
    "    for i, j in itertools.combinations(range(num_qubits), 2):\n",
    "        if restricted:\n",
    "            if i<n_visible and j>=n_visible:\n",
    "                pauli_string = ['I'] * num_qubits\n",
    "    \n",
    "                pauli_string[i] = 'Z'\n",
    "                pauli_string[j] = 'Z'\n",
    "                pauli_strings.append(''.join(pauli_string))\n",
    "        else:\n",
    "            if i<n_visible:\n",
    "                \n",
    "                pauli_string = ['I'] * num_qubits\n",
    "                \n",
    "                pauli_string[i] = 'Z'\n",
    "                pauli_string[j] = 'Z'\n",
    "                   \n",
    "                pauli_strings.append(''.join(pauli_string))       \n",
    "    return pauli_strings\n",
    "\n",
    "\n",
    "class QBM():\n",
    "    \"\"\"Quantum Boltzmann machine (QBM) based on quantum signal processing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    β, enc:\n",
    "        Same as attributes.\n",
    "    h, θ:\n",
    "        See qbmqsp.hamiltonian.Hamiltonian\n",
    "    δ, polydeg:\n",
    "        See qbmqsp.qsp_phase_engine.QSPPhaseEngine\n",
    "    hnodes : Number of hidden nodes\n",
    "    epochs: Number of epochs to train\n",
    "    restricted (bool): [default] True\n",
    "    \n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    β : float\n",
    "        Inverse temperature.\n",
    "    enc : str in {'general', 'lcu'}\n",
    "        Unitary block encoding scheme.\n",
    "    H : qbmqsp.hamiltonian.Hamiltonian\n",
    "        Constructed from parameters (h, θ).\n",
    "    qsp : qbmqsp.qsp_phase_engine.QSPPhaseEngine\n",
    "        Constructed from parameters (δ, polydeg).\n",
    "    qevt : qbmqsp.qevt.QEVT\n",
    "        Quantum eigenvalue transform to realize matrix function f(A) = exp(- τ * |A|). Updated after each training epoch.\n",
    "    observables : qml.operation.Observable\n",
    "        Observables w.r.t which the QBM is measured to optimize via gradient descent.\n",
    "    aux_wire, enc_wires, sys_wires, env_wires : list[int]\n",
    "        Quantum register wires of quantum circuit that prepares and measures the QBM.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self,data,h: list[str], θ: np.ndarray[float], enc: str, δ: float, polydeg: int, β: float, hnodes,epochs=1,restricted=True) -> None:\n",
    "        if β < 0:\n",
    "            raise ValueError(\"__init__: β must not be negative.\")\n",
    "        \n",
    "        self.epochs=epochs\n",
    "        self.β = β\n",
    "        self.enc = enc\n",
    "        self.H = Hamiltonian(h, θ)\n",
    "        self.qsp = QSPPhaseEngine(δ, polydeg)\n",
    "        self.qevt = self._construct_qevt()\n",
    "        self.aux_wire, self.enc_wires, self.sys_wires, self.env_wires = self._construct_wires()\n",
    "        self.observables = self._construct_obervables()\n",
    "        \n",
    "        self.encoded_data, bits_input_vector, num_features = self.binary_encode_data(data, use_folding=True)\n",
    "        self.dim_input = bits_input_vector * num_features\n",
    "        self.quantile=0.95\n",
    "        \n",
    "        self.n_hidden_nodes=hnodes\n",
    "        \n",
    "        self.qubits=self.dim_input+self.n_hidden_nodes\n",
    "        \n",
    "        self.restricted=restricted\n",
    "\n",
    "        if self.restricted:\n",
    "            self.weights_visible_to_hidden=np.reshape(self.H.θ[self.dim_input+self.n_hidden_nodes:],(self.dim_input,self.n_hidden_nodes))\n",
    "            self.biases_hidden=self.H.θ[self.dim_input:self.dim_input+self.n_hidden_nodes]\n",
    "            self.biases_visible=self.H.θ[:self.dim_input]\n",
    "        else:\n",
    "            \n",
    "            self.weights_visible_to_visible,self.weights_visible_to_hidden=self.get_weights(self.H.θ)\n",
    "            self.biases_hidden=self.H.θ[self.dim_input:self.dim_input+self.n_hidden_nodes]\n",
    "            self.biases_visible=self.H.θ[:self.dim_input]\n",
    "        \n",
    "\n",
    "    def get_binary_cluster_points(self,dataset, cluster_index: int) -> np.ndarray:\n",
    "        points = np.array([entry[:-1]\n",
    "                           for entry in dataset if entry[-1] <= cluster_index])\n",
    "\n",
    "        return self.binary_encode_data(points, use_folding=False)[0]\n",
    "    \n",
    "    def get_binary_outliers(self,dataset, outlier_index: int):\n",
    "        outliers = np.array([entry[:-1]\n",
    "                            for entry in dataset if entry[-1] >= outlier_index])\n",
    "\n",
    "        return self.binary_encode_data(outliers, use_folding=False)[0]\n",
    "  \n",
    "    def binary_encode_data(self,data, use_folding=False):\n",
    "        \"\"\" Encode a numpy array of form [[numpy.int64 numpy.int64] ...] into a\n",
    "        list of form [[int, int, int, ...], ...].\n",
    "        Example: encode [[107  73] [113  90] ...] to\n",
    "        [[1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1],[1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0] .\n",
    "        \"\"\"\n",
    "\n",
    "        # find out how many bits we need for each feature\n",
    "        number_bits = len(np.binary_repr(np.amax(data)))\n",
    "        number_features = data.shape[1]\n",
    "\n",
    "        binary_encoded = ((data.reshape(-1, 1) & np.array(2 **\n",
    "                          np.arange(number_bits-1, -1, -1))) != 0).astype(np.float32)\n",
    "        if use_folding:\n",
    "            return binary_encoded.reshape(len(data), number_features*number_bits), number_bits, number_features\n",
    "        else:\n",
    "            return binary_encoded.reshape(len(data), number_features, number_bits), number_bits, number_features\n",
    "    \n",
    "    \n",
    "    def n_qubits(self, registers: str | set[str] = None) -> int:\n",
    "        \"\"\"Return number of qubits per registers.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        registers : str | set[str]\n",
    "            Quantum registers whose number of qubits should be returned.\n",
    "            Must be an element from or a subset of {'aux', 'enc', 'sys', 'env'}.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        n : int\n",
    "            Number of qubits used per registers.\n",
    "        \"\"\"\n",
    "        if registers is None:\n",
    "            registers = {'aux', 'enc', 'sys', 'env'}\n",
    "        elif type(registers) == str:\n",
    "            registers = {registers}\n",
    "        if not registers.issubset({'aux', 'enc', 'sys', 'env'}):\n",
    "            raise ValueError(\"n_qubits: registers must be an element from or a subset of %r.\" % {'aux', 'enc', 'sys', 'env'})\n",
    "        \n",
    "        n = 0\n",
    "        if 'env' in registers:\n",
    "            n += self.qevt.n_qubits('sys')\n",
    "        registers.discard('env')\n",
    "        if len(registers) != 0:\n",
    "            n += self.qevt.n_qubits(registers)\n",
    "        return n\n",
    "\n",
    "    def _generate_qsp_phases(self) -> np.ndarray[float]:\n",
    "        τ = self.β / (1-self.qsp.δ) * self.H.θ_norm()\n",
    "        φ = self.qsp.generate(τ)\n",
    "        return φ\n",
    "\n",
    "    def _construct_qevt(self) -> QEVT:\n",
    "        φ = self._generate_qsp_phases()\n",
    "        h_δ, θ_δ = self.H.preprocessing(self.qsp.δ)\n",
    "        return QEVT(h_δ, θ_δ, self.enc, φ)\n",
    "    \n",
    "    def _construct_wires(self) -> tuple[list[int], list[int], list[int], list[int]]:\n",
    "        wires = list(range(self.n_qubits()))\n",
    "        aux_wire = wires[: self.n_qubits('aux')]\n",
    "        enc_wires = wires[self.n_qubits('aux') : self.n_qubits({'aux', 'enc'})]\n",
    "        sys_wires = wires[self.n_qubits({'aux', 'enc'}) : self.n_qubits({'aux', 'enc', 'sys'})]\n",
    "        env_wires = wires[self.n_qubits({'aux', 'enc', 'sys'}) : self.n_qubits({'aux', 'enc', 'sys', 'env'})]\n",
    "        return aux_wire, enc_wires, sys_wires, env_wires\n",
    "\n",
    "    def _construct_obervables(self) -> list[qml.operation.Observable]:\n",
    "        n_aux_enc = self.n_qubits({'aux', 'enc'})\n",
    "        aux_enc_wires = self.aux_wire + self.enc_wires\n",
    "        proj0 = qml.Projector( [0] * n_aux_enc, aux_enc_wires)\n",
    "\n",
    "        new_sys_wires = list(range(self.n_qubits('sys')))\n",
    "        wire_map = dict(zip(self.sys_wires, new_sys_wires))\n",
    "        observables = [proj0] + [proj0 @ string_to_pauli_word(self.H.h[i], wire_map) for i in range(self.H.n_params)]\n",
    "        return observables\n",
    "    \n",
    "    def _bell_circuit(self) -> None:\n",
    "        for i, j in zip(self.sys_wires, self.env_wires):\n",
    "            qml.Hadamard(i)\n",
    "            qml.CNOT([i, j])\n",
    "\n",
    "    def probabilistic(self):\n",
    "        \n",
    "        bit_strings=[]\n",
    "        for i in range(2**(self.n_hidden_nodes+self.dim_input)):\n",
    "        # Convert the number to its binary representation and pad with leading zeros\n",
    "            bit_string = bin(i)[2:].zfill(self.n_hidden_nodes+self.dim_input)\n",
    "             \n",
    "            bit_list = np.array([int(bit) for bit in bit_string])\n",
    "            bit_strings.append(bit_list) \n",
    "            \n",
    "      \n",
    "        sample = random.choices(bit_strings, k=1)\n",
    "\n",
    "        for i,x in enumerate(sample[0]):\n",
    "            if x==1:\n",
    "                qml.PauliX(wires=[self.sys_wires[i]])\n",
    "    \n",
    "    def _prepare(self) -> None:\n",
    "        self._bell_circuit()\n",
    "        #self.probabilistic()\n",
    "        self.qevt.circuit(self.aux_wire, self.enc_wires, self.sys_wires)\n",
    "    \n",
    "    def _measure(self) -> None:\n",
    "        #return qml.sample(wires=self.aux_wire+self.enc_wires+self.sys_wires)\n",
    "        \n",
    "        return [qml.expval(self.observables[i]) for i in range(len(self.observables))]\n",
    "    \n",
    "    \n",
    "    def get_sample(self,shots=1):\n",
    "        dev = qml.device(dev_name,shots=shots, wires=self.n_qubits({'aux','enc','sys'}))\n",
    "        @qml.qnode(dev)\n",
    "        \n",
    "        def quantum_circuit():\n",
    "            \n",
    "            self._prepare()\n",
    "            return qml.sample(wires=self.aux_wire+self.enc_wires+self.sys_wires)\n",
    "        \n",
    "        sample=quantum_circuit()\n",
    "        return sample\n",
    "    \n",
    "    def get_average_configuration_from_samples(self, samples: list, input_vector=None):\n",
    "        ''' Takes samples from Annealer and averages for each neuron and connection\n",
    "        '''\n",
    "\n",
    "        # unclamped if input_vector == None\n",
    "        unclamped = input_vector== None\n",
    "\n",
    "        # biases (row = sample, column = neuron)\n",
    "        np_samples = np.vstack(\n",
    "            tuple([np.array(list(sample.values())) for sample in samples]))\n",
    "        avgs_biases = np.average(np_samples, axis=0)\n",
    "        avgs_biases_hidden = avgs_biases[self.dim_input:] if unclamped else avgs_biases\n",
    "        avgs_biases_visible = avgs_biases[:\n",
    "                                          self.dim_input] if unclamped else input_vector\n",
    "\n",
    "        # weights\n",
    "        avgs_weights_visible_to_hidden = np.zeros(\n",
    "            self.weights_visible_to_hidden.shape)\n",
    "        if not self.restricted:\n",
    "            avgs_weights_visible_to_visible = np.zeros(\n",
    "                self.weights_visible_to_visible.shape)\n",
    "        for v in range(self.dim_input):\n",
    "            # visible to hidden connections\n",
    "            for h in range(self.n_hidden_nodes):\n",
    "                x, y = (np_samples[:, v], self.dim_input +\n",
    "                        h) if unclamped else (input_vector[v], h)\n",
    "                avgs_weights_visible_to_hidden[v, h] = np.average(\n",
    "                    x*np_samples[:, y])\n",
    "            # visible to visible connections\n",
    "            if not self.restricted:\n",
    "                for v2 in range(v, self.dim_input):\n",
    "                    x, y = (np_samples[:, v], np_samples[:, v2]) if unclamped else (\n",
    "                        input_vector[v], input_vector[v2])\n",
    "                    avgs_weights_visible_to_visible[v, v2] = np.average(x*y)\n",
    "\n",
    "        if self.restricted:\n",
    "            return avgs_biases_hidden, avgs_biases_visible, avgs_weights_visible_to_hidden, None\n",
    "        else:\n",
    "            return avgs_biases_hidden, avgs_biases_visible, avgs_weights_visible_to_hidden, avgs_weights_visible_to_visible\n",
    "\n",
    "    def _compute_expvals(self) -> np.ndarray[float]:\n",
    "        dev = qml.device(dev_name,wires=self.n_qubits({'aux','enc','sys','env'}))\n",
    "        #dev = qml.device(dev_name, backend=backend,wires=self.n_qubits(),ibmqx_token=token)\n",
    "        @qml.qnode(dev)\n",
    "        \n",
    "        def quantum_circuit():\n",
    "            self._prepare()\n",
    "            if dev_name=='default.qubit':\n",
    "                return self._measure()\n",
    "            else:\n",
    "                observation_wires=[[]]\n",
    "                \n",
    "                for term in self.H.h:\n",
    "                    list=[]\n",
    "                    for i,el in enumerate(term):\n",
    "                        if el!='I':\n",
    "                            list.append(i+self.n_qubits({'aux','enc'}))\n",
    "                    observation_wires.append(list)\n",
    "                \n",
    "                probabilities=[qml.probs(wires=[0,1]+wires) for wires in observation_wires]\n",
    "\n",
    "                return probabilities\n",
    "                \n",
    "            \n",
    "        \n",
    "        if dev_name=='default.qubit':\n",
    "        \n",
    "            measurements = quantum_circuit()\n",
    "            \n",
    "            success_probability = measurements[0]\n",
    "           \n",
    "            \n",
    "            qbm_expvals = measurements[1:] / success_probability\n",
    "            \n",
    "            return qbm_expvals\n",
    "        \n",
    "        else:\n",
    "\n",
    "            probabilities=quantum_circuit()\n",
    "            success_probability=probabilities[0][0]\n",
    "            print(success_probability)\n",
    "            rest_probabilites=probabilities[1:]\n",
    "            exp_val=[]\n",
    "            for i,term in enumerate(rest_probabilites):\n",
    "                if i<self.n_hidden_nodes+self.dim_input:\n",
    "                \n",
    "                    ps=np.reshape(term,(4,2))[0]\n",
    "                \n",
    "                    exp_val.append(ps[0]-ps[1])\n",
    "                else:\n",
    "                \n",
    "                    ps=np.reshape(term,(4,4))[0]\n",
    "        \n",
    "                    exp_val.append(ps[0]-ps[1]-ps[2]+ps[3])      \n",
    "            \n",
    "        \n",
    "        \n",
    "       \n",
    "            return np.array(exp_val)/success_probability\n",
    "    \n",
    "    def _loss_func(self, ρ0: np.ndarray[float], ρ1: np.ndarray[float]) -> float:\n",
    "        return relative_entropy(ρ0, ρ1, check_state=True).item()\n",
    "    \n",
    "    def assemble(self) -> np.ndarray[float]:\n",
    "        \"\"\"Assemble QBM.\"\"\"\n",
    "        expH = spl.expm(-self.β * self.H.assemble())\n",
    "        return expH / np.trace(expH)\n",
    "    \n",
    "    \n",
    "    def get_energy(self,input_vector,k=30,method='min'):\n",
    "        input_vector=[input_vector]\n",
    "        new_biases=self.biases_hidden+np.matmul(1-2*np.array(input_vector),self.weights_visible_to_hidden).flatten()\n",
    "        \n",
    "        \n",
    "    # List to store all bit strings\n",
    "        bit_strings=[]\n",
    "        p=[]\n",
    "    # There are 2^n bit strings of length n\n",
    "        #print(new_biases)\n",
    "        for i in range(2**self.n_hidden_nodes):\n",
    "        # Convert the number to its binary representation and pad with leading zeros\n",
    "            bit_string = bin(i)[2:].zfill(self.n_hidden_nodes)\n",
    "             \n",
    "            bit_list = np.array([1-2*int(bit) for bit in bit_string])\n",
    "            bit_strings.append(bit_list) \n",
    "            p.append(np.exp(-self.β*np.dot(bit_list,new_biases)))\n",
    "\n",
    "        p=np.array(p)\n",
    "         \n",
    "        replacement_value = 1000000\n",
    "\n",
    "\n",
    "        is_inf = np.isinf(p)\n",
    "\n",
    "# Replace infinite values with the replacement value\n",
    "        p[is_inf] = replacement_value\n",
    "        probabilities=p/np.sum(p)\n",
    "        \n",
    "        sample = random.choices(bit_strings, weights=probabilities, k=k)\n",
    "        energies=np.dot(sample,new_biases)\n",
    "        \n",
    "        if method=='min':\n",
    "            return np.min(energies)    \n",
    "        else:\n",
    "            \n",
    "             \n",
    "            avg_energy=np.sum(probabilities*np.dot(np.array(bit_strings),new_biases))\n",
    "            return avg_energy\n",
    "            \n",
    "\n",
    "               \n",
    "\n",
    "            \n",
    "     \n",
    "    \n",
    "    def free_energy(self,method='min',input_vector=None):\n",
    "        '''Function to compute the free energy'''\n",
    "\n",
    "        # calculate hidden term\n",
    "        \n",
    "         \n",
    "        if self.n_hidden_nodes==0: \n",
    "            hidden_term = 0\n",
    "        else:\n",
    "            hidden_term = self.get_energy(method=method,input_vector=input_vector)\n",
    "        # calculate visible_term\n",
    "        # visible bias\n",
    "        visible_term = np.dot(\n",
    "            1-2*np.array(input_vector), self.H.θ[:self.dim_input]) #/beta\n",
    "        \n",
    "        pos_neg=1-2*input_vector\n",
    "        if self.restricted==False:\n",
    "             \n",
    "             \n",
    "             vv_interaction=np.matmul(self.weights_visible_to_visible,pos_neg)\n",
    "             vv_interaction=np.matmul(pos_neg.T,vv_interaction)\n",
    "             visible_term=visible_term+vv_interaction\n",
    "        \n",
    "\n",
    "        return hidden_term + visible_term\n",
    "    \n",
    "    def calculate_outlier_threshold(self, quantile=0.95,method='min'):\n",
    "        \n",
    "        self.quantile = quantile\n",
    "        energy_func=partial(self.free_energy,method)\n",
    "        \n",
    "        energies = np.apply_along_axis(\n",
    "            energy_func, axis=1, arr=self.encoded_data)\n",
    "        \n",
    "        self.outlier_threshold = np.quantile(energies, self.quantile)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_average_configurations(self,input_vector=None):\n",
    "        '''\n",
    "        Function for giving averge configurations of all qubits for the gibbs state of the system.\n",
    "        \n",
    "        If input vector is clamped at a certain value , it gives configuration of hidden units only.\n",
    "       \n",
    "    \n",
    "        Parameters:\n",
    "        input vector (np.ndarray)\n",
    "        \n",
    "    \n",
    "        Returns:\n",
    "        list: List of expectation values of hamilatonian terms.\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        # unclamped values\n",
    "        if input_vector is None:\n",
    "            \n",
    "            qbm_expvals=self._compute_expvals()\n",
    "            \n",
    "            return qbm_expvals\n",
    "        \n",
    "        # clamped values\n",
    "        \n",
    "        \n",
    "        if self.restricted:\n",
    "            self.weights_visible_to_hidden=np.reshape(self.H.θ[self.dim_input+self.n_hidden_nodes:],(self.dim_input,self.n_hidden_nodes))\n",
    "            self.biases_hidden=self.H.θ[self.dim_input:self.dim_input+self.n_hidden_nodes]\n",
    "            self.biases_visible=self.H.θ[:self.dim_input]\n",
    "        else:\n",
    "            \n",
    "            self.weights_visible_to_visible,self.weights_visible_to_hidden=self.get_weights(self.H.θ)\n",
    "            self.biases_hidden=self.H.θ[self.dim_input:self.dim_input+self.n_hidden_nodes]\n",
    "            self.biases_visible=self.H.θ[:self.dim_input]\n",
    "        \n",
    "        input_vector=[input_vector]\n",
    "        new_biases=self.biases_hidden+np.matmul(1-2*np.array(input_vector),self.weights_visible_to_hidden).flatten()\n",
    "        #np.matmul(input_vector, self.weights_visible_to_hidden).flatten()\n",
    "        \n",
    "        Q_new=new_biases\n",
    "\n",
    "        exp_vals=-np.tanh(self.β*new_biases)\n",
    "        return exp_vals\n",
    "            \n",
    "       \n",
    "        \n",
    "        \n",
    "    def train_for_one_iteration(self, batch, learning_rate):\n",
    "\n",
    "        '''\n",
    "        Performs the update for one batch in the dataset.\n",
    "\n",
    "        Parameters:\n",
    "\n",
    "        batch \n",
    "        learning_rate\n",
    "       \n",
    "        Returns:\n",
    "        list: List of avg errors in the visible configuration for each element of the batch.\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        errors = 0\n",
    "        #errors_biases_visible = 0\n",
    "        #errors_weights_visible_to_hidden = 0\n",
    "        #if not self.restricted:\n",
    "          #  errors_weights_visible_to_visible = 0\n",
    "\n",
    "        for i,input_vector in enumerate(batch):\n",
    "            \n",
    "            \n",
    "            if i==0:\n",
    "                unclamped_config = self.get_average_configurations() \n",
    "                #print(unclamped_config)\n",
    "            \n",
    "            clamped_config = self.get_average_configurations(input_vector) # has only expectations over hidden units\n",
    "            \n",
    "            # avgs_weights_visible_to_visible_clamped only has a value if not restricted\n",
    "            #print(clamped_config)\n",
    "            \n",
    "            # Getting averages for all qubits , avg_visible=input_vector\n",
    "            \n",
    "            full_clamped_config=np.zeros_like(unclamped_config)\n",
    "            \n",
    "            full_clamped_config[:self.dim_input]=1+(-2)*input_vector   \n",
    "            full_clamped_config[self.dim_input:self.dim_input+self.n_hidden_nodes]=clamped_config\n",
    "            \n",
    "            pos_neg=1-2*input_vector\n",
    "            if self.restricted:\n",
    "                \n",
    "                \n",
    "                full_clamped_config[self.dim_input+self.n_hidden_nodes:]=np.kron(pos_neg,clamped_config)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                \n",
    "                \n",
    "                visible=list(pos_neg[j]*pos_neg[i] for j in range(len(pos_neg)) for i in range(j+1,len(pos_neg)))\n",
    "                hidden=np.kron(pos_neg,clamped_config)\n",
    "                for i in range(1,self.dim_input+1):\n",
    "                    for j in range(self.n_hidden_nodes):\n",
    "                        visible.insert((i-1)*self.n_hidden_nodes+(i)*(self.dim_input-1)-(i-1)+j,hidden[self.n_hidden_nodes*(i-1)+j])\n",
    "                full_clamped_config[self.dim_input+self.n_hidden_nodes:]=np.array(visible)\n",
    "            \n",
    "            errors += full_clamped_config - unclamped_config\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "        errors /= batch.shape[0]\n",
    "        \n",
    "        self.H.θ = self.H.θ - learning_rate * errors \n",
    "                \n",
    "        self.qevt = self._construct_qevt()\n",
    "                \n",
    "       \n",
    "        \n",
    "        \n",
    "        return np.average(errors[:self.dim_input]**2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def train_model(self, batch_size=8, learning_rate=0.005,save=False):\n",
    "        \n",
    "        data = self.encoded_data\n",
    "        \n",
    "        weights=[]\n",
    "        batch_num = data.shape[0] // batch_size\n",
    "        diff = data.shape[0] % batch_size\n",
    "        self.batch_size=batch_size\n",
    "        \n",
    "        if diff:\n",
    "            \n",
    "        \n",
    "            data = data[:-diff]\n",
    "            last_batch = data[data.shape[0] - diff:]\n",
    "        \n",
    "        \n",
    "        \n",
    "        batches = np.vsplit(data, batch_num)\n",
    "        \n",
    "        if diff:\n",
    "            batches.append(last_batch)\n",
    "              \n",
    "        losses=[]\n",
    "        \n",
    "        for epoch in range(1, self.epochs+1):\n",
    "            print(f'Epoch {epoch}')\n",
    "            batch_errors = None\n",
    "            batchnum = 1\n",
    "            errors_epoch=[]\n",
    "            for batch in tqdm(batches):\n",
    "                    #print(batch)\n",
    "                    errors = self.train_for_one_iteration(batch, learning_rate)\n",
    "                    \n",
    "                    if type(batch_errors) is np.ndarray:\n",
    "                        batch_errors = np.hstack((batch_errors, errors))\n",
    "                    else:\n",
    "                        batch_errors = errors\n",
    "                    #self.save_weights(\n",
    "                        #f'e{epoch}_b{batchnum}_{self.paramstring}')\n",
    "                    batchnum += 1\n",
    "               \n",
    "                    #self.save_weights(\n",
    "                     #   f'e{epoch}_b{batchnum}_{self.paramstring}')\n",
    "                    #raise e\n",
    "                    errors_epoch.append(errors)\n",
    "            \n",
    "            losses.append(errors_epoch)\n",
    "            weights.append(self.H.θ)\n",
    "            if save==True:\n",
    "                try:\n",
    "                    np.savez(f'./epoch{epoch}_weights_h{self.n_hidden_nodes}_v{self.dim_input}_lr{self.learning_rate}_e{self.epochs}',self.H.θ)\n",
    "                    np.savez(f'./epoch{epoch}_losses_h{self.n_hidden_nodes}_v{self.dim_input}_lr{self.learning_rate}_e{self.epochs}',errors_epoch)\n",
    "                except:\n",
    "                    print('error_saving')\n",
    "        self.calculate_outlier_threshold(self.quantile)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return losses, weights \n",
    "    \n",
    "    #self.error_container.add_error(batch_errors)\n",
    "        #self.error_container.plot(\"qbm_errors\" + self.paramstring)\n",
    "        #self.save_weights(title=\"final_weights_qbm\" + self.paramstring)\n",
    "        # make list of values of the error dicts\n",
    "        \n",
    "        #self.calculate_outlier_threshold(self.quantile)\n",
    "       \n",
    "    def predict_point_as_outlier(self, input,method):\n",
    "        energy = self.free_energy(method,input)\n",
    "        if energy >= self.outlier_threshold:\n",
    "            return 1, energy\n",
    "        return 0, energy\n",
    "        \n",
    "    \n",
    "    def get_weights(self,Q):\n",
    "        weights_vh_vv=list(Q[self.dim_input+self.n_hidden_nodes:])\n",
    "            \n",
    "        for i in range(1,self.dim_input+1):\n",
    "            for j in range(i):\n",
    "                weights_vh_vv.insert((self.dim_input+self.n_hidden_nodes)*(i-1)+j,0)\n",
    "            \n",
    "        weights_vh_vv=np.array(weights_vh_vv)\n",
    "        weights_visible_to_visible=weights_vh_vv.reshape(self.dim_input,self.dim_input+self.n_hidden_nodes)[:,0:self.dim_input]\n",
    "        weights_visible_to_hidden=weights_vh_vv.reshape(self.dim_input,self.dim_input+self.n_hidden_nodes)[:,self.dim_input:]\n",
    "    \n",
    "        return weights_visible_to_visible,weights_visible_to_hidden\n",
    "    \n",
    "    def save_model(path,dataset_name):\n",
    "         path=Path(path/dataset)\n",
    "         path.mkdir(exist_ok=True)\n",
    "         np.savez(f'_e{qbm.epochs}_h{qbm.n_hidden_nodes}_v{qbm.dim_input}_b{qbm.batch_size}',qbm.H.θ)\n",
    "        \n",
    "     \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae4339fc-6a9a-4d31-9372-70d0fda848a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_qbm(qbm,testing_dataset,cluster,plot=False,quantile=0.95,method='min'):\n",
    "\n",
    "\n",
    "    #training_data=numpy.expand_dims(training_data[:,0],axis=1)\n",
    "    outliers = qbm.get_binary_outliers(\n",
    "    dataset=testing_dataset, outlier_index=cluster)\n",
    "\n",
    "    #outliers=numpy.expand_dims(outliers[:,0],axis=1)\n",
    "    \n",
    "\n",
    "    points = qbm.get_binary_cluster_points(\n",
    "    dataset=testing_dataset, cluster_index=cluster-1)\n",
    "\n",
    "    #points=numpy.expand_dims(points[:,0],axis=1)\n",
    "    #print(points)\n",
    "    predict_points_cluster = np.zeros(len(points), dtype=int)\n",
    "    predict_points_outliers = np.zeros(len(outliers), dtype=int)\n",
    "    qbm.calculate_outlier_threshold(quantile, method)\n",
    "    print(\"Outlier threshold: \", qbm.outlier_threshold)\n",
    "    print(\"Calculate outlier Energy\")\n",
    "\n",
    "    testing_data, testing_labels = split_dataset_labels(testing_dataset)\n",
    "#testing_data=numpy.expand_dims(testing_data[:,0],axis=1)\n",
    "\n",
    "    outlier_energy = []\n",
    "    for index, outlier in enumerate(tqdm(outliers), 0):\n",
    "        outlier = np.reshape(outlier, (qbm.dim_input))\n",
    "        predict_points_outliers[index], this_outlier_energy = qbm.predict_point_as_outlier(\n",
    "            outlier,method)\n",
    "        outlier_energy.append(this_outlier_energy)\n",
    "    outlier_energy = np.array(outlier_energy)\n",
    "\n",
    "    o = outlier_energy.reshape((outlier_energy.shape[0]))\n",
    "\n",
    "    print(\"Calculate cluster energy\")\n",
    "    cluster_point_energy = []\n",
    "\n",
    "    for index, point in enumerate(tqdm(points), 0):\n",
    "        point = np.reshape(point, (qbm.dim_input))\n",
    "        predict_points_cluster[index], this_cluster_point_energy = qbm.predict_point_as_outlier(\n",
    "        point,method)\n",
    "        cluster_point_energy.append(this_cluster_point_energy)\n",
    "    cluster_point_energy = np.array(cluster_point_energy)\n",
    "\n",
    "    c = cluster_point_energy.reshape((cluster_point_energy.shape[0]))\n",
    "\n",
    "    title='test'\n",
    "#qbmqsp.src.utils.save_output(title=\"cluster_\" + title, object=c)\n",
    "#QBM.plot_energy_diff([o, c], qbm.outlier_threshold, title + \".pdf\")\n",
    "\n",
    "#QBM.plot_hist(c, o, qbm.outlier_threshold, \"qbm_hist\" + \".pdf\")\n",
    "\n",
    "########## OUTLIER CLASSIFICATION ##########\n",
    "    print('Outlier classification: Results...')\n",
    "    predict_points = np.concatenate(\n",
    "        (predict_points_cluster, predict_points_outliers))\n",
    "\n",
    "    print(\"Predicted points test: \", predict_points)\n",
    "\n",
    "    true_points = np.concatenate(\n",
    "        (np.zeros_like(cluster_point_energy), np.ones_like(outlier_energy)))\n",
    "\n",
    "    accuracy, precision, recall = accuracy_score(true_points, predict_points), precision_score(\n",
    "        true_points, predict_points), recall_score(true_points, predict_points)\n",
    "    f1 = f1_score(true_points, predict_points)\n",
    "    tn, fp, fn, tp = confusion_matrix(\n",
    "        true_points, predict_points, labels=[0, 1]).ravel()\n",
    "\n",
    "    print(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}, \\nNum True Negative: {tn}, Num False Negative: {fn}, Num True Positive: {tp}, Num False Positive: {fp}')\n",
    "\n",
    "#print(f'Wallclock time: {(end-start):.2f} seconds')\n",
    "    lab=cluster-1\n",
    "    print(\"Outlier threshold: \", qbm.outlier_threshold)\n",
    "    print(\"Average clusterpoint energy: \", np.average(cluster_point_energy))\n",
    "    print(\"Outlier energy: \", outlier_energy)\n",
    "    \n",
    "    if plot==True:\n",
    "        plt.figure()\n",
    "        plt.title('Test Dataset')\n",
    "        sns.scatterplot(x=testing_data[:,0],y=testing_data[:,1])\n",
    "        sns.scatterplot(x=testing_data[:,0][testing_labels>lab],y=testing_data[:,1][testing_labels>lab], c='r',palette='coolwarm')\n",
    "        \n",
    "    #plt.title('Predicted Points')\n",
    "    #sns.scatterplot(x=testing_data[:,0],y=testing_data[:,1], hue=predict_points,palette='coolwarm')\n",
    "    return [[accuracy],[precision],[recall],[f1],[tn],[fp],[fn],[tp]] \n",
    "\n",
    "\n",
    "def perform_run(seed=77, n_hidden_nodes=1, sample_count=20,\n",
    "        beta_eff=1, epochs=2, batch_size=9, learning_rate=0.005,\n",
    "         restricted=True, save_path=None, name=\"\"):\n",
    "\n",
    "    '''\n",
    "    Performs training and testing of the QBM for one set of parameters.\n",
    "    '''    \n",
    "    global data\n",
    "    global training_dataset\n",
    "    global training_labels\n",
    "    global testing_dataset\n",
    "    global testing_labels\n",
    "    global dev_name\n",
    "    \n",
    "    print(\"Start\")\n",
    "\n",
    "\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    \n",
    "    data = import_dataset(PATH)\n",
    "    training_dataset, testing_dataset = split_data(data, CLUSTER)\n",
    "    training_data, training_labels = split_dataset_labels(training_dataset)\n",
    "    testing_data, testing_labels = split_dataset_labels(testing_dataset)\n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "    print(\"Seed is \" + str(seed))\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    \n",
    "    param_string = \"_se\" + str(seed) + \"_h\" + str(n_hidden_nodes) + \"_b\" + str(\n",
    "        beta_eff) + \"_e\" + str(epochs) + \"_l\" + str(learning_rate) + \"_r\" + str(restricted) + \"_n_\" + name\n",
    "\n",
    "    # create DQBM\n",
    "        \n",
    "    n_visible=8\n",
    "    n_qubits = n_visible+n_hidden_nodes\n",
    "\n",
    "    \n",
    "    h = generate_pauli_strings_tfim(n_qubits,n_visible,restricted)\n",
    "    nparams=len(h)\n",
    "\n",
    "    θ_init =np.random.rand(nparams)/nparams#np.loadtxt('./weights_7_3_un.txt')\n",
    "    enc = 'general'\n",
    "    δ = 0.3\n",
    "    polydeg = 10\n",
    "    \n",
    "   \n",
    "    \n",
    "    dev_name='default.qubit'\n",
    "\n",
    "\n",
    "    qbm = QBM(training_data,h, θ_init, enc, δ, polydeg,beta_eff,n_hidden_nodes,epochs,restricted)\n",
    "    \n",
    "    print('Training QBM...')\n",
    "    errors,weights=qbm.train_model(batch_size,learning_rate)\n",
    "\n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "    final_metrics=evaluate_qbm(qbm,testing_dataset,CLUSTER,plot=False,quantile=0.95,method='mean')\n",
    "    \n",
    "    if save_path is not None:\n",
    "        \n",
    "        try:\n",
    "       \n",
    "            path=Path(save_path)/param_string\n",
    "            path.mkdir(exist_ok=True)\n",
    "            np.save('errors.npy',errors)\n",
    "            np.save('weights.npy',weights)\n",
    "            np.save('training_dataset.npy',training_dataset)\n",
    "            np.save('metrics.npy',np.array(final_metrics))\n",
    "        except:\n",
    "            print('Error Saving')\n",
    "    \n",
    "    \n",
    "    return final_metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bacbce9e-70bf-4dd7-af31-a3ed1361b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averages(list_of_lists):\n",
    "    array_of_arrays = np.array(list_of_lists)\n",
    "    averages = np.mean(array_of_arrays, axis=0)\n",
    "    return averages\n",
    "\n",
    "\n",
    "\n",
    "def configure_hyperparams(run):\n",
    "    '''\n",
    "    Sets the hyperparameters for a given run. Both with\n",
    "    and without hyperparameter optimisation.\n",
    "    '''\n",
    "    \n",
    "    global BATCH_SIZE\n",
    "    global EPOCHS\n",
    "    \n",
    "    \n",
    "    global N_HIDDEN_UNITS\n",
    "    global SAMPLE_COUNT\n",
    "    global BETA_EFF\n",
    "    global LEARNING_RATE\n",
    "    #global BASEPATH_RECORD\n",
    "    global RESTRICTED\n",
    "    global PARAM_STRING\n",
    "    #global ARGUMENTS\n",
    "\n",
    "    if run:\n",
    "        \n",
    "        config_defaults = {'batchsize': args.batchsize, 'epochs': args.epochs,'hnodes': args.hnodes,\n",
    "                            'beta_eff': args.beta_eff,\n",
    "                           'restricted':args.restricted, 'learning_rate':args.learning_rate\n",
    "                           }\n",
    "    \n",
    "        run.config.setdefaults(config_defaults)\n",
    "\n",
    "        # set hyperparameters from sweep\n",
    "        BATCH_SIZE = wandb.config.batchsize\n",
    "        EPOCHS = wandb.config.epochs\n",
    "        LEARNING_RATE=wandb.config.learning_rate\n",
    "        # define network parameters for dqbm\n",
    "        N_HIDDEN_UNITS = wandb.config.hnodes\n",
    "       \n",
    "        BETA_EFF = wandb.config.beta_eff\n",
    "        \n",
    "        RESTRICTED=wandb.config.restricted\n",
    "       \n",
    "    else:\n",
    "        # set hyperparameters\n",
    "        BATCH_SIZE = args.batchsize\n",
    "        EPOCHS = args.epochs\n",
    "        LEARNING_RATE=args.learning_rate\n",
    "\n",
    "        # define network parameters for dqbm\n",
    "        N_HIDDEN_UNITS = args.hnodes\n",
    "      \n",
    "        BETA_EFF = args.beta_eff\n",
    "        RESTRICTED=args.restricted\n",
    "        \n",
    "     # params and identifier-strings independent of using hyperparameter\n",
    "    # optimization or not\n",
    "    #BASEPATH_RECORD = get_basepath(\"training\", DATASET)\n",
    "    \n",
    "    #ARGUMENTS = [BATCH_SIZE, EPOCHS, ACCURACY_INTERVAL,\n",
    "             #   N_HIDDEN_UNITS, SAMPLE_COUNT, ANNEAL_STEPS, BETA_EFF, TESTSIZE]\n",
    "    \n",
    "    PARAM_STRING = \"_h\" + str(N_HIDDEN_UNITS) +\"_ba\"+str(BATCH_SIZE) +\"_b\" + str(\n",
    "        BETA_EFF)+\"_lr\"+str(LEARNING_RATE) + \"_e\" + str(EPOCHS) + \"_r\" + str(RESTRICTED)\n",
    "    \n",
    "    \n",
    "    return PARAM_STRING\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    \n",
    "  \n",
    "   \n",
    "    \n",
    "\n",
    "    NUM_RUNS = args.n_runs\n",
    "\n",
    "    # start run\n",
    "    if HYPERPARAM_OPT:\n",
    "        run = wandb.init(reinit=True\n",
    "                         , group=SWEEP_ID\n",
    "                         )\n",
    "    else:\n",
    "        run = None\n",
    "\n",
    "    param_string_for_run=configure_hyperparams(run)\n",
    "    \n",
    "    #is_first_run = args.first_run\n",
    "\n",
    "    PARAM_STRING_SEED=param_string_for_run\n",
    "    \n",
    "     \n",
    "\n",
    "    \n",
    "    if HYPERPARAM_OPT:\n",
    "        \n",
    "        \n",
    "        \n",
    "        num_metrics=8   #number of metric returned by the perform_run function\n",
    "        metrics_for_all_seeds=[[] for i in range(num_metrics)]\n",
    "    \n",
    "    seeds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 13, 14, 15, 16, 17, 18, 19, 21, 22,\n",
    "             23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n",
    "             40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 55, 56, 58,\n",
    "             60, 61, 62, 63, 64, 65, 66, 70, 71, 72, 73, 74, 75, 76, 77, 78,\n",
    "             79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 92, 93, 96, 97, 98, 99]\n",
    "\n",
    "    NUM_RUNS=4\n",
    "    \n",
    "    for run_num in range(NUM_RUNS):\n",
    "        # determine seed\n",
    "        seed = random.choice(seeds)\n",
    "        \n",
    "        print(\"seed: \" + str(seed))\n",
    "        \n",
    "        PARAM_STRING_SEED = PARAM_STRING_SEED+ \"_s\" + str(seed)\n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "        metrics=perform_run(epochs=EPOCHS, n_hidden_nodes=N_HIDDEN_UNITS    ,\n",
    "            batch_size=BATCH_SIZE,beta_eff=BETA_EFF,\n",
    "            learning_rate=LEARNING_RATE, restricted=RESTRICTED,\n",
    "            seed=seed,save_path=args.save_path)\n",
    "        \n",
    "      \n",
    "\n",
    "        if HYPERPARAM_OPT:\n",
    "            # get combined metric of accuracy and auc-roc-score\n",
    "            #combined_metrics = get_combined_metrics(metrics[0], metrics[5])\n",
    "            #metrics.append(combined_metrics)\n",
    "            \n",
    "             for metric_index in range(len(metrics)):\n",
    "                metrics_for_all_seeds[metric_index].append(metrics[metric_index])\n",
    "\n",
    "        print(f\"Training for seed {seed} done.\\n\")\n",
    "        seeds.remove(seed)\n",
    "    \n",
    "    \n",
    "    if HYPERPARAM_OPT:\n",
    "        #print(metrics_for_all_seeds)\n",
    "        \n",
    "        run.name = PARAM_STRING_SEED\n",
    "        \n",
    "        print(f\"Run Name: {run.name}\\n\")\n",
    "        \n",
    "        for metric_index in range(len(metrics_for_all_seeds)):\n",
    "            metrics_for_all_seeds[metric_index] = get_averages(metrics_for_all_seeds[metric_index])\n",
    "        #print(metrics_for_all_seeds)\n",
    "        \n",
    "        print(metrics_for_all_seeds)\n",
    "        #for i in range(len(metrics_for_all_seeds[0])):\n",
    "        wandb.log({\n",
    "                       'accuracy': metrics_for_all_seeds[0].item(),\n",
    "                   'precision': metrics_for_all_seeds[1].item(), 'recall': metrics_for_all_seeds[2].item(),\n",
    "                   'f1_score': metrics_for_all_seeds[3].item(), 'true_negatives': metrics_for_all_seeds[4].item(),\n",
    "                   'false_positives': metrics_for_all_seeds[5].item(),\n",
    "                       'false_negatives': metrics_for_all_seeds[6].item(),\n",
    "                   'true_positives': metrics_for_all_seeds[7].item()}\n",
    "                  )\n",
    "        run.finish()\n",
    "    print(\"Run done.\")\n",
    "\n",
    "#print(\"Seeds from list left: \", seeds)\n",
    "         \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a409fa9-5705-4c3e-9930-b05bf273b3ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: nt3eg153\n",
      "Sweep URL: https://wandb.ai/shivang_arora/Gate-qbm-anomaly-detection/sweeps/nt3eg153\n",
      "Gate-qbm-anomaly-detection/nt3eg153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tv5kxwba with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta_eff: 2.1943747394819004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thnodes: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.4486039988792957\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ge84gac\\Gate_qbm\\tests\\wandb\\run-20240726_225103-tv5kxwba</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shivang_arora/Gate-qbm-anomaly-detection/runs/tv5kxwba' target=\"_blank\">prime-sweep-1</a></strong> to <a href='https://wandb.ai/shivang_arora/Gate-qbm-anomaly-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/shivang_arora/Gate-qbm-anomaly-detection/sweeps/nt3eg153' target=\"_blank\">https://wandb.ai/shivang_arora/Gate-qbm-anomaly-detection/sweeps/nt3eg153</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shivang_arora/Gate-qbm-anomaly-detection' target=\"_blank\">https://wandb.ai/shivang_arora/Gate-qbm-anomaly-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/shivang_arora/Gate-qbm-anomaly-detection/sweeps/nt3eg153' target=\"_blank\">https://wandb.ai/shivang_arora/Gate-qbm-anomaly-detection/sweeps/nt3eg153</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shivang_arora/Gate-qbm-anomaly-detection/runs/tv5kxwba' target=\"_blank\">https://wandb.ai/shivang_arora/Gate-qbm-anomaly-detection/runs/tv5kxwba</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 21\n",
      "Start\n",
      "Seed is 21\n",
      "\n",
      "Starting MATLAB engine.. Done.\n",
      "\n",
      "Training QBM...\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [11:29<00:00, 17.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████                                     | 22/40 [06:21<05:10, 17.28s/it]"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import wandb\n",
    "CLUSTER=5\n",
    "PATH= '../../datasets/good_datasets/l_o8_c5_d2_v0.35_p190_4.npy'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = 'sweep_' + 'bayes_qbm12_long' \n",
    "\n",
    "sweep_configuration = {'name': name,\n",
    "                       'description': '',\n",
    "                       'project': \"qbm-anomaly-detection\", 'entity': \"shivang_arora\",\n",
    "                       'method': 'bayes',\n",
    "                       'metric': {'goal': 'maximize', 'name':\n",
    "                           'f1_score'},\n",
    "                       'parameters': {'batchsize': {'max': 90, 'min': 7},\n",
    "                                      'epochs': {'max': 15, 'min': 1},\n",
    "                                      'learning_rate': {'max': 0.9, 'min': 0.1},\n",
    "                                      'beta_eff':{'max':2.5 ,'min':1.0},\n",
    "                                     \n",
    "                                      'hnodes': {'max':2, 'min':1 },\n",
    "                                      },\n",
    "                        \n",
    "                       # min_iter same number as accuracy-interval?\n",
    "                       #'early_terminate': {'type': 'hyperband', 'min_iter': 4}\n",
    "                       \n",
    "                       }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Generate clustered datasets with outliers.')\n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "    parser.add_argument('-hn', '--hnodes',\n",
    "                        metavar='INT',\n",
    "                        help='Amount of hidden units for RBM model',\n",
    "                        default=1,  # best fit for dataset l_o7_c5_d3_p200_v1\n",
    "                        type=int)\n",
    "\n",
    "    parser.add_argument('-e', '--epochs',\n",
    "                        metavar='INT',\n",
    "                        help='Epochs for training',\n",
    "                        default=2,  # best fit for dataset l_o7_c5_d3_p200_v1\n",
    "                        type=int)\n",
    "\n",
    "    parser.add_argument('-b', '--batchsize',\n",
    "                        metavar='INT',\n",
    "                        help='Batchsize for training',\n",
    "                        default=9,  # best fit for dataset l_o7_c5_d3_p200_v1\n",
    "                        type=int)\n",
    "\n",
    "    \n",
    "   \n",
    "    # random seed for reproducibility of classical (SA) runs\n",
    "    \n",
    "    parser.add_argument('-s', '--seed',\n",
    "                        metavar='INT',\n",
    "                        help='Seed for RNG',\n",
    "                        default=77,  # best fit for dataset l_o7_c5_d3_p200_v1\n",
    "                        type=int)\n",
    "\n",
    " \n",
    "\n",
    "    parser.add_argument('--save_path',\n",
    "                        help='Filepath to save',\n",
    "                        default=None,\n",
    "                        type=str)\n",
    "\n",
    "    parser.add_argument('--name',\n",
    "                        help='Name for run',\n",
    "                        default=\"\",\n",
    "                        type=str)\n",
    "\n",
    "    #parser.add_argument(\"--sample_count\", type=int, default=20)\n",
    "   \n",
    "    # number of annealing steps to perform (only relevant for SA)\n",
    "    \n",
    " \n",
    "   \n",
    "    # inverse effective temperature, only relevant for runs on D-Wave\n",
    "    \n",
    "    # (What is good default value? 0.5? 1.0? ...?)\n",
    "    parser.add_argument(\"--beta_eff\", type=float, default=1.0)\n",
    "\n",
    "   \n",
    "\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=0.005)\n",
    "    \n",
    "    parser.add_argument(\"--restricted\", type=str, default='false')\n",
    "\n",
    "  \n",
    "    \n",
    "    parser.add_argument(\"--n_runs\", type=int, default=2)\n",
    "\n",
    "    # for automized hyperparameter optimization\n",
    "    \n",
    "    parser.add_argument(\"--hyperparam_opt\", type=str, default='true')\n",
    "    parser.add_argument(\"--n_sweeps\", type=int, default=500)\n",
    "    parser.add_argument(\"--sweep_id\", type=str, default=None)\n",
    "    \n",
    "    #Add sweep id , through a separate sweep file instead.\n",
    "    \n",
    "    parser.add_argument(\"--key\", type=str, default=None)\n",
    "    \n",
    "    args = parser.parse_args([])\n",
    "    \n",
    "    \n",
    "    HYPERPARAM_OPT = args.hyperparam_opt == 'true'\n",
    "    NUM_SWEEPS = args.n_sweeps\n",
    "\n",
    "    \n",
    "    \n",
    "    if HYPERPARAM_OPT:\n",
    "        #wandb.login(key=args.key)\n",
    "        wandb.login()\n",
    "        \n",
    "        #SWEEP_ID = args.sweep_id\n",
    "        \n",
    "        #sweep_id_path = \"mdsg/qbm-anomaly-detection/\" + SWEEP_ID\n",
    "        \n",
    "        project_name='Gate-qbm-anomaly-detection' \n",
    "        entity='shivang_arora'\n",
    "        # add entity name\n",
    "        sweep_id_path=wandb.sweep(sweep_configuration,project=project_name,entity=entity)    \n",
    "        #sweep_id_path='sweep_'+''\n",
    "        sweep_id_path=project_name+'/'+sweep_id_path\n",
    "        print(sweep_id_path)\n",
    "        SWEEP_ID=sweep_id_path\n",
    "        main_with_args = partial(main, args)\n",
    "        wandb.agent(sweep_id=sweep_id_path, function=main_with_args,\n",
    "                    count=NUM_SWEEPS)\n",
    "    else:\n",
    "        main(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80018eef-4664-4d16-bcef-83d74a3c0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b5e8f-f94f-4285-a2d7-57f1c0e80983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
